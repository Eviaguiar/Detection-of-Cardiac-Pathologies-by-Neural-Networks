# -*- coding: utf-8 -*-
"""NEWREDUWU.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1cu8ZR_HJMXCTjNVpgOjD8fR-9vRVOpNC

# Introduction
A couple of months ago Keras added CuDNNLSTM and CuDNNGRU layers, which are special implementations of the regular LSTM and GRU layers backed by NVIDIA's cuDNN library. This means that if you have access to a CUDA GPU, training recurrent neural networks just got a whole lot faster.

In this blogpost I'll be showing a simple implementation of an LSTM network and compare the computations times of a network implemented in the CuDDNLSTM layer with one implemented with the regular LSTM layer. I will also be using this opportunity to explore the PTB Diagnostic ECG Database (https://www.physionet.org/physiobank/database/ptbdb/), a database containing ECG data of 290 subjects of which some have a particular heart disease.

# Recurrent neural networks & LSTMs
"""

from google.colab import drive
drive.mount('/content/gdrive/', force_remount=True)

!pip install wfdb
!pip install tensorflow

# Commented out IPython magic to ensure Python compatibility.
from wfdb import io, plot
import os
import numpy as np
import matplotlib.pyplot as plt
from tqdm import tqdm_notebook as tqdm
# %matplotlib notebook
import pandas as pd
import math
#import tensorflow as tf
import keras
from keras.models import Sequential
from keras.layers import Dense
from keras.layers import Dropout, Input
from keras.layers import LSTM
from keras.layers.cudnn_recurrent import CuDNNLSTM
from keras.callbacks import ModelCheckpoint
from sklearn.utils import shuffle
from sklearn.metrics import confusion_matrix
import time

record_names=[record.record_name ]

lst=[patient_id]
############################

def record_to_row(record, patient_id):
    row = {}
    row['patient'] = patient_id
    row['name'] = record.record_name
    row['label'] = comments_to_dict(record.comments)['Reason for admission'][1:]
    row['signals'] = record.p_signal
    row['signal_length'] = record.sig_len
    channels = record.sig_name
    print (channels)
    signals = record.p_signal.transpose()
    row['channels'] = channels
    
    for channel, signal in zip(channels, signals):
        row[channel] = signal
        
    return row

def comments_to_dict(comments):
    key_value_pairs = [comment.split(':') for comment in comments]
    return {pair[0]: pair[1] for pair in key_value_pairs}

records = []
count=0
for record_name in tqdm(record_names):
    record = io.rdrecord(record_name=os.path.join('gdrive/Shareddrives/Tesis: ECG e Imágenes sECG/ptb-xl-dataset/records500/', record_name),channels = [6,7,8,9,10,11])
    label = lst[count]
    patient = record_name.split('/')[0]
    signal_length = record.sig_len
    records.append({'name':record_name, 'label':label, 'patient':patient, 'signal_length':signal_length})
    count=count+1
    
channels = record.sig_name
df_records = pd.DataFrame(records)

channels

records[1]

labels = df_records['label'].unique()
df_records['label'].value_counts()

df_records['signal_length'].min()

Others=['Hypertrophy','Valvular heart disease','Myocarditis','Stable angina','Unstable angina',
        'Heart failure (NYHA 4)','Heart failure (NYHA 2)','Heart failure (NYHA 3)','Palpitation']

#selected_labels = ['Healthy control','Myocardial infarction','Bundle branch block','Cardiomyopathy','Dysrhythmia','Others' ]
df_selected = df_records.loc[df_records['label'].isin(labels)]
label_map = {label: value for label, value in zip(labels, range(len(labels)))}

df_selected

test_patients = []
train_patients = []
test_size = 0.2 #0.2
channels
for label in labels:
    df_selected = df_records.loc[df_records['label'] == label]
    patients = df_selected['patient'].unique()
    n_test = math.ceil(len(patients)*test_size)
    test_patients+=list(np.random.choice(patients, n_test, replace=False))
    train_patients+=list(patients[np.isin(patients, test_patients, invert=True)])

def make_set(df_data, channels, label_map, record_id, window_size=2000): #window_size=2048
    n_windows = 0
    
    for _, record in tqdm(df_data.iterrows()):
        n_windows+= record['signal_length']//window_size

    dataX = np.zeros((n_windows, len(channels), window_size))
    dataY = np.zeros((n_windows, len(label_map)))
    
    record_list = []
    
    nth_window = 0
    for i, (patient, record) in enumerate(tqdm(df_data.iterrows())):
        # read the record, get the signal data and transpose it
        signal_data = io.rdrecord(os.path.join('gdrive/Shareddrives/Tesis: ECG e Imágenes sECG/ptb-xl-dataset/records500/', record['name']),channels = [6,7,8,9,10,11])
        signal_data = signal_data.p_signal.transpose() 
        n_rows = signal_data.shape[-1]
        n_windows = n_rows//window_size
        dataX[nth_window:nth_window+n_windows] = np.array([signal_data[:,i*window_size:(i+1)*window_size] for i in range(n_windows)])
        dataY[nth_window:nth_window+n_windows][:, label_map[record.label]] = 1
        nth_window+=n_windows
        
        if record_id:
            record_list+= n_windows*[record['name']]
        
    return dataX, dataY, record_list

label_map

df_patient_records = df_records.set_index('patient')
df_train_patients = df_patient_records.loc[train_patients]
df_test_patients = df_patient_records.loc[test_patients]
window_size = 2000 #df_records['signal_length'].min() window_size = 2048
trainX, trainY, _ = make_set(df_train_patients, channels, label_map, False, window_size)
testX, testY, record_list = make_set(df_test_patients, channels, label_map, True, window_size)

trainX

a=testX[0]
a[0]
len(a)

from keras.optimizers import Adam
op = Adam(lr=0.001)

def make_model(input_shape, output_dim, lstm_layer, dropout=0.2):
    print("model dim: ", input_shape, output_dim)
    model = Sequential()
    model.add(lstm_layer(256, return_sequences=True, input_shape=input_shape, batch_size=None))
    model.add(Dropout(dropout))
    model.add(lstm_layer(128, return_sequences=True))
    model.add(Dropout(dropout))
    model.add(LSTM(64))
    model.add(Dropout(dropout))
    model.add(Dense(output_dim, activation='softmax'))
    model.compile(loss= 'categorical_crossentropy', optimizer='adam', metrics=['accuracy'])
    #'categorical_crossentropy''adam'
    return model

def make_model(input_shape, output_dim, lstm_layer, dropout=0.2):
    print("model dim: ", input_shape, output_dim)
    model = Sequential()
    model.add(lstm_layer(256, return_sequences=True, input_shape=input_shape, batch_size=None))
    model.add(Dropout(dropout))
    model.add(lstm_layer(128, return_sequences=True))
    model.add(Dropout(dropout))
    model.add(LSTM(64))
    model.add(Dropout(dropout))
    
    model.add(Dense(32,activation = 'relu'))
    model.add(Dropout(0.2))
    
    model.add(Dense(output_dim, activation='softmax'))
    model.compile(loss= 'categorical_crossentropy', optimizer='adam', metrics=['accuracy'])

    return model

np.random.seed(1337)

#Shuffle order of train set
trainX, trainY = shuffle(trainX, trainY)

#Since we have a large class inbalance we need to udjust the weights for it.
fractions = 1-trainY.sum(axis=0)/len(trainY)
weights = fractions[trainY.argmax(axis=1)]

model = make_model((trainX.shape[1], trainX.shape[2]), trainY.shape[-1], LSTM)

weights

trainY[-1]

"""epochs=42, batch_size=512 train 1522 test 367

*   Elemento de lista
*   Elemento de lista



> Bloque con sangría


"""

dnn= model.fit(trainX, trainY, epochs=20, batch_size=700, sample_weight=weights, validation_data=(testX, testY))

model.summary()

from keras.utils.vis_utils import plot_model
plot_model(model, to_file='model_plot.png', show_shapes=True, show_layer_names=True)

# evaluate the model
loss, accuracy = model.evaluate(trainX, trainY, verbose=0)
print('Accuracy: %f' % (accuracy*100))

model.evaluate(testX, testY)

#output = model().predict_classes(testX)
predict_x=model.predict(testX) 
output=np.argmax(predict_x,axis=1)

model.save('gdrive/Shared drives/Tesis: ECG e Imágenes sECG/ptb-xl-dataset/models/signals_cnn_hmn')

from sklearn.metrics import confusion_matrix
conf_mat=confusion_matrix(testY.argmax(axis=1), output)
print(conf_mat)

# Commented out IPython magic to ensure Python compatibility.
# %matplotlib inline

from mlxtend.plotting import plot_confusion_matrix
y_labels_vals = ['MI', 'STTC', 'CD','HYP', 'NORM']
fig, ax = plot_confusion_matrix(conf_mat)
plt.title('Confusion matrix of the classifier: RED 1')
ax.set_xticklabels([''] + y_labels_vals)
ax.set_yticklabels([''] + y_labels_vals)
plt.show()

import matplotlib.pyplot as plt
plt.figure(0)  
plt.plot(dnn.history['accuracy'])  
plt.plot(dnn.history['val_accuracy'])    
plt.rcParams['figure.figsize'] = (8, 6)  
plt.xlabel("Num of Epochs")  
plt.ylabel("Accuracy")  
plt.title("Training Accuracy vs Validation Accuracy")  
plt.legend(['train','validation'])

plt.figure(1)  
plt.plot(dnn.history['loss'])  
plt.plot(dnn.history['val_loss'])   
plt.rcParams['figure.figsize'] = (8, 6)  
plt.xlabel("Num of Epochs")  
plt.ylabel("Loss")  
plt.title("Training Loss vs Validation Loss")  
plt.legend(['train','validation'])

plt.show()
