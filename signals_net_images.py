# -*- coding: utf-8 -*-
"""signals_net_images.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1KwZEOVNBWYUctqW5cCAWxPYpiY1Bs1JZ

# Detection of cardiac patologies in sECG signals images using Convolutional Neural Networks

First, we start by import the last version of fastai repository and all the libraries that are required.
"""

!pip install fastai --upgrade -q
from fastai import *
from fastai.vision import *
from fastai.vision.data import *
from fastai.data.all import *
from fastai.vision.all import *
from fastai.metrics import error_rate
from fastai.vision.data import ImageDataLoaders

"""Then, we have to import the data seth path"""

from google.colab import drive
drive.mount('/content/gdrive', force_remount=True)

root_dir = 'gdrive/Shared drives/Tesis: ECG e Imágenes sECG/Red 2/'
base_dir = root_dir + 'BASENEW125'
path=Path(base_dir)

print(path)

path.ls()

#bs = 164
#bs = 16   # uncomment this line if you run out of memory even after clicking Kernel->Restart
batch_size=14

"""
Now we load our images in an ImageDataBucnh object. This object allows us to load the images direct from the folders, load the images with the same sizes, define the images per batch, identify the ones that are used for training, validation and test. Also, it makes the transformations required."""

fields = DataBlock(blocks=(ImageBlock, CategoryBlock), get_items=get_image_files,get_y=parent_label, splitter=RandomSplitter(),item_tfms = Resize(224))

dls=fields.dataloaders(path,bs=batch_size)

dls.vocab

dls.train.show_batch(max_n=8,nrows=2)

"""Now we visualize examples of the images with the fucntion 'show_batch'. It shows random images.

This shows the number of train images, validation set, test set and label targets.
"""

dls.c, len(dls.train_ds), len(dls.valid_ds)

dls.train_ds[1][1]

"""Now, we have to select the size of our batch (one of our hyperparameters). It is basically the quantity of images per group that we are passing to our net.

# Model used to detect EMG siganls images.

We decided to use RESNET34 as the model, and error_rate as the metric.
"""

learn = cnn_learner(dls, models.resnet34, loss_func=CrossEntropyLossFlat(), lr=0.001, metrics=[accuracy, error_rate])

learn.summary()

learn.model

"""We set 4 epochs. That mean the number o times that our data is going forward and backward. (Weights update). Too many epochs can produce overfitting, then the net just learn to recognize this set of images but cannot generalize with new images."""

learn.fit_one_cycle(10)

preds,targs = learn.tta()
accuracy(preds, targs).item()

plot_model(learn.model, to_file='model_plot.png', show_shapes=True, show_layer_names=False)
Image('model_plot.png')

"""Save the trained model"""

dest=path + "/models/signalshmn/")
try:
  dest.mkdir(parents=True, exist_ok=False)
  print('Saved')
except FileExistsError:
  print ('File Already Exists')

learn.save(path/'signals_cnn_hmn')

"""Now we have to analyze the results"""

interp = ClassificationInterpretation.from_learner(learn)

"""This show us how good was our prediction"""

interp.plot_top_losses(9, figsize=(15,11))

"""Confusion matrix where the positive diagonal is the number of right targets that we got. """

interp.plot_confusion_matrix(figsize=(6,6), dpi=80)

interp.most_confused(min_val=2)

"""Unfreezing, fine-tuning and learning rates"""

learn.unfreeze()

from fastai.callback.schedule import lr_find
learn.lr_find()
plt.title("Learning Rate")
plt.show()
learn.recorder.plot_loss()
plt.title("Loss Rate")
plt.show()

learn.unfreeze()
learn.fit_one_cycle(20, lr_max=slice(10e-6, 10e-5)) #3e-5, 3e-4

preds,targs = learn.tta()
accuracy(preds, targs).item()

learn.save(dest/'signals_stage2_41epochs_2020_07_17')

learn.recorder.plot_losses()

interp = ClassificationInterpretation.from_learner(learn)

interp.plot_top_losses(9, figsize=(20,11))

interp.plot_confusion_matrix(figsize=(6,6), dpi=80)

interp.most_confused(min_val=2)

learn.lr_find()
plt.title("Learning Rate")
plt.show()
learn.recorder.plot_loss()
learn.recorder.plot_sched()
plt.title("Loss Rate")
plt.show()

dls.train_ds[1][1]

x_test=[]
for i in dls.train_ds:

  x_test.append(dls.valid_ds[i][1])
print (x_test)

import matplotlib.pyplot as plt  
from sklearn import datasets, metrics, model_selection, svm
X, y = datasets.make_classification(random_state=0)
X_train, X_test, y_train, y_test = model_selection.train_test_split(X, y, random_state=0)
clf = svm.SVC(random_state=0)
clf.fit(X_train, y_train)

metrics.plot_roc_curve(clf, X_test, y_test)  
plt.show()

img = learn.data.test_ds[15][0]
img

learn.predict(img)

learn.export(dest/'deploy_stage2_41epochs_2020_07_17')

"""# Steps to run our model preview

Cargamos las librerías y configuramos variables de path a los modelos y data
"""

!curl -s https://course.fast.ai/setup/colab | bash

pathModel = Path('gdrive/Shared drives/Signals EMG/models/signalshmn/')

learner2 = load_learner(pathModel, 'deploy_stage2_41epochs_2020_07_17')

"""## Aquí pasamos la imagen que queremos predecir

Usaremos la carpeta con imágenes de test para probar el modelo.
"""

pathData = Path('gdrive/Shared drives/Signals EMG/dataset/EMGB/gray1.jpg')

img = open_image(pathData)
print(img.data.shape)
img.show()

"""pasamos la imagen al modelo entrenado y obtenemos de resultado tensor 0 o 1"""

learner2.predict(img)

en caso de no recordar que es tensor 0 o 1 imprimimos las clases que le corresponde

print(data.classes[0])
print(data.classes[1])

"""0 = covid , y 1 = nocovid"""